<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>AI Assistant - Voice Chat</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            min-height: 100vh;
            color: white;
            overflow: hidden;
            position: relative;
        }
        
        /* Avatar Container */
        #avatar-container {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: 1;
        }
        
        iframe {
            width: 100%;
            height: 100%;
            border: none;
        }
        
        /* Voice Control Overlay */
        #voice-overlay {
            position: fixed;
            bottom: 0;
            left: 0;
            right: 0;
            padding: 20px;
            background: linear-gradient(transparent, rgba(0,0,0,0.8));
            z-index: 10;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 15px;
        }
        
        /* Main Button */
        #mic-button {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%);
            color: white;
            font-size: 32px;
            cursor: pointer;
            box-shadow: 0 4px 20px rgba(59, 130, 246, 0.4);
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        #mic-button:hover {
            transform: scale(1.05);
            box-shadow: 0 6px 30px rgba(59, 130, 246, 0.6);
        }
        
        #mic-button:active {
            transform: scale(0.95);
        }
        
        #mic-button.recording {
            background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
            box-shadow: 0 4px 20px rgba(239, 68, 68, 0.4);
            animation: pulse 1s infinite;
        }
        
        #mic-button.speaking {
            background: linear-gradient(135deg, #10b981 0%, #059669 100%);
            box-shadow: 0 4px 20px rgba(16, 185, 129, 0.4);
        }
        
        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.1); }
        }
        
        /* Status Display */
        #status-display {
            background: rgba(0, 0, 0, 0.6);
            backdrop-filter: blur(10px);
            padding: 12px 24px;
            border-radius: 25px;
            font-size: 14px;
            text-align: center;
            min-width: 200px;
            max-width: 90%;
        }
        
        #status-display .status-text {
            color: #4ade80;
            font-weight: 500;
        }
        
        #status-display .transcript {
            color: white;
            margin-top: 5px;
            font-size: 13px;
            opacity: 0.9;
        }
        
        /* Conversation Log */
        #conversation-log {
            position: fixed;
            top: 20px;
            left: 20px;
            right: 20px;
            max-height: 30vh;
            overflow-y: auto;
            z-index: 10;
            display: flex;
            flex-direction: column;
            gap: 10px;
        }
        
        .message {
            background: rgba(0, 0, 0, 0.6);
            backdrop-filter: blur(10px);
            padding: 10px 15px;
            border-radius: 15px;
            max-width: 80%;
            animation: slideIn 0.3s ease;
        }
        
        .message.user {
            align-self: flex-end;
            background: rgba(59, 130, 246, 0.3);
            border: 1px solid rgba(59, 130, 246, 0.5);
        }
        
        .message.assistant {
            align-self: flex-start;
            background: rgba(16, 185, 129, 0.3);
            border: 1px solid rgba(16, 185, 129, 0.5);
        }
        
        .message .sender {
            font-size: 11px;
            opacity: 0.7;
            margin-bottom: 3px;
        }
        
        .message .text {
            font-size: 14px;
            line-height: 1.4;
        }
        
        @keyframes slideIn {
            from {
                opacity: 0;
                transform: translateY(-10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }
        
        /* Loading Spinner */
        .spinner {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(255,255,255,.3);
            border-radius: 50%;
            border-top-color: #fff;
            animation: spin 1s ease-in-out infinite;
        }
        
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
        
        /* Permission Request */
        #permission-request {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(0, 0, 0, 0.9);
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            z-index: 100;
            padding: 20px;
            text-align: center;
        }
        
        #permission-request h2 {
            margin-bottom: 20px;
            font-size: 24px;
        }
        
        #permission-request p {
            margin-bottom: 30px;
            opacity: 0.8;
            line-height: 1.6;
        }
        
        #permission-request button {
            padding: 15px 40px;
            font-size: 18px;
            background: linear-gradient(135deg, #3b82f6 0%, #2563eb 100%);
            color: white;
            border: none;
            border-radius: 30px;
            cursor: pointer;
            box-shadow: 0 4px 20px rgba(59, 130, 246, 0.4);
        }
        
        .hidden {
            display: none !important;
        }
    </style>
</head>
<body>
    <!-- Permission Request -->
    <div id="permission-request">
        <h2>üé§ „Éû„Ç§„ÇØ„ÅÆË®±ÂèØ„ÅåÂøÖË¶Å„Åß„Åô</h2>
        <p>AI„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„Å®Èü≥Â£∞„Åß‰ºöË©±„Åô„Çã„Å´„ÅØ„ÄÅ<br>„Éû„Ç§„ÇØ„Å∏„ÅÆ„Ç¢„ÇØ„Çª„Çπ„ÇíË®±ÂèØ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ</p>
        <button onclick="requestPermission()">Ë®±ÂèØ„Åô„Çã</button>
    </div>
    
    <!-- Avatar -->
    <div id="avatar-container">
        <iframe src="https://meeting-ai-avatar.netlify.app" id="avatar-frame"></iframe>
    </div>
    
    <!-- Conversation Log -->
    <div id="conversation-log"></div>
    
    <!-- Voice Control Overlay -->
    <div id="voice-overlay">
        <div id="status-display">
            <div class="status-text">„Çø„ÉÉ„Éó„Åó„Å¶Ë©±„Åó„Åã„Åë„Çã</div>
            <div class="transcript"></div>
        </div>
        <button id="mic-button" onclick="toggleRecording()">üé§</button>
    </div>

    <script>
        // Configuration
        const OPENAI_API_KEY = 'YOUR_OPENAI_API_KEY'; // „É¶„Éº„Ç∂„Éº„Å´Ë®≠ÂÆö„Åó„Å¶„ÇÇ„Çâ„ÅÜ
        
        // State
        let isRecording = false;
        let recognition = null;
        let audioContext = null;
        let mediaRecorder = null;
        let audioChunks = [];
        
        // DOM Elements
        const micButton = document.getElementById('mic-button');
        const statusDisplay = document.getElementById('status-display');
        const statusText = statusDisplay.querySelector('.status-text');
        const transcriptText = statusDisplay.querySelector('.transcript');
        const conversationLog = document.getElementById('conversation-log');
        const permissionRequest = document.getElementById('permission-request');
        const avatarFrame = document.getElementById('avatar-frame');
        
        // Initialize Speech Recognition
        function initSpeechRecognition() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) {
                alert('„Åä‰Ωø„ÅÑ„ÅÆ„Éñ„É©„Ç¶„Ç∂„ÅØÈü≥Â£∞Ë™çË≠ò„Çí„Çµ„Éù„Éº„Éà„Åó„Å¶„ÅÑ„Åæ„Åõ„Çì„ÄÇSafari„Åæ„Åü„ÅØChrome„Çí„Åä‰Ωø„ÅÑ„Åè„Å†„Åï„ÅÑ„ÄÇ');
                return false;
            }
            
            recognition = new SpeechRecognition();
            recognition.lang = 'ja-JP';
            recognition.continuous = false;
            recognition.interimResults = true;
            
            recognition.onstart = () => {
                isRecording = true;
                micButton.classList.add('recording');
                statusText.textContent = 'ËÅû„ÅÑ„Å¶„ÅÑ„Åæ„Åô...';
                transcriptText.textContent = '';
                
                // Notify avatar
                notifyAvatar('listening');
            };
            
            recognition.onresult = (event) => {
                let transcript = '';
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    transcript += event.results[i][0].transcript;
                }
                transcriptText.textContent = transcript;
            };
            
            recognition.onend = () => {
                if (isRecording) {
                    const finalTranscript = transcriptText.textContent;
                    if (finalTranscript.trim()) {
                        handleUserMessage(finalTranscript);
                    }
                    stopRecording();
                }
            };
            
            recognition.onerror = (event) => {
                console.error('Recognition error:', event.error);
                statusText.textContent = '„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü';
                stopRecording();
            };
            
            return true;
        }
        
        // Request Permission
        async function requestPermission() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                stream.getTracks().forEach(track => track.stop());
                
                permissionRequest.classList.add('hidden');
                
                if (initSpeechRecognition()) {
                    statusText.textContent = 'Ê∫ñÂÇôÂÆå‰∫ÜÔºÅ„Çø„ÉÉ„Éó„Åó„Å¶Ë©±„Åó„Åã„Åë„Å¶„Åè„Å†„Åï„ÅÑ';
                }
            } catch (err) {
                alert('„Éû„Ç§„ÇØ„Å∏„ÅÆ„Ç¢„ÇØ„Çª„Çπ„ÅåÊãíÂê¶„Åï„Çå„Åæ„Åó„Åü„ÄÇË®≠ÂÆö„Åã„ÇâË®±ÂèØ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ');
            }
        }
        
        // Toggle Recording
        function toggleRecording() {
            if (!recognition) {
                requestPermission();
                return;
            }
            
            if (isRecording) {
                recognition.stop();
            } else {
                try {
                    recognition.start();
                } catch (err) {
                    console.error('Failed to start recognition:', err);
                }
            }
        }
        
        function stopRecording() {
            isRecording = false;
            micButton.classList.remove('recording');
        }
        
        // Handle User Message
        async function handleUserMessage(text) {
            // Add to conversation log
            addMessage('user', text);
            
            statusText.textContent = 'ËÄÉ„Åà‰∏≠...';
            transcriptText.textContent = '';
            
            // Notify avatar
            notifyAvatar('thinking');
            
            try {
                // Call OpenAI API
                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${OPENAI_API_KEY}`
                    },
                    body: JSON.stringify({
                        model: 'gpt-4o-mini',
                        messages: [
                            { role: 'system', content: '„ÅÇ„Å™„Åü„ÅØÊó•Êú¨Ë™û„Åß‰∏ÅÂØß„Å´Á≠î„Åà„ÇãAI„Ç¢„Ç∑„Çπ„Çø„É≥„Éà„Åß„Åô„ÄÇÁ∞°ÊΩî„Å´Á≠î„Åà„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ' },
                            { role: 'user', content: text }
                        ],
                        max_tokens: 150
                    })
                });
                
                const data = await response.json();
                const reply = data.choices[0].message.content;
                
                // Display and speak
                addMessage('assistant', reply);
                speak(reply);
                
            } catch (err) {
                console.error('API error:', err);
                statusText.textContent = '„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü';
            }
        }
        
        // Add Message to Log
        function addMessage(sender, text) {
            const msgDiv = document.createElement('div');
            msgDiv.className = `message ${sender}`;
            msgDiv.innerHTML = `
                <div class="sender">${sender === 'user' ? '„ÅÇ„Å™„Åü' : '„Ç¢„Ç∑„Çπ„Çø„É≥„Éà'}</div>
                <div class="text">${text}</div>
            `;
            conversationLog.appendChild(msgDiv);
            conversationLog.scrollTop = conversationLog.scrollHeight;
        }
        
        // Text to Speech
        async function speak(text) {
            statusText.textContent = 'Ë©±„Åó„Å¶„ÅÑ„Åæ„Åô...';
            micButton.classList.add('speaking');
            
            // Notify avatar
            notifyAvatar('speaking_start', text);
            
            try {
                const response = await fetch('https://api.openai.com/v1/audio/speech', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${OPENAI_API_KEY}`
                    },
                    body: JSON.stringify({
                        model: 'tts-1',
                        input: text,
                        voice: 'nova'
                    })
                });
                
                const audioBlob = await response.blob();
                const audioUrl = URL.createObjectURL(audioBlob);
                const audio = new Audio(audioUrl);
                
                audio.onended = () => {
                    micButton.classList.remove('speaking');
                    statusText.textContent = '„Çø„ÉÉ„Éó„Åó„Å¶Ë©±„Åó„Åã„Åë„Çã';
                    notifyAvatar('speaking_end');
                };
                
                await audio.play();
                
            } catch (err) {
                // Fallback to browser TTS
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = 'ja-JP';
                utterance.onend = () => {
                    micButton.classList.remove('speaking');
                    statusText.textContent = '„Çø„ÉÉ„Éó„Åó„Å¶Ë©±„Åó„Åã„Åë„Çã';
                    notifyAvatar('speaking_end');
                };
                speechSynthesis.speak(utterance);
            }
        }
        
        // Notify Avatar (via postMessage to iframe)
        function notifyAvatar(type, data = null) {
            avatarFrame.contentWindow.postMessage({
                type: type,
                data: data
            }, '*');
        }
        
        // Check for API key
        if (OPENAI_API_KEY === 'YOUR_OPENAI_API_KEY') {
            // Try to get from localStorage
            const savedKey = localStorage.getItem('openai_api_key');
            if (savedKey) {
                OPENAI_API_KEY = savedKey;
            } else {
                const key = prompt('OpenAI API Key„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ:');
                if (key) {
                    OPENAI_API_KEY = key;
                    localStorage.setItem('openai_api_key', key);
                }
            }
        }
    </script>
</body>
</html>
