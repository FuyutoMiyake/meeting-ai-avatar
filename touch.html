<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <title>AI Assistant - Voice Touch</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            -webkit-tap-highlight-color: transparent;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(180deg, #0a0a1a 0%, #1a1a2e 100%);
            min-height: 100vh;
            color: white;
            overflow: hidden;
            touch-action: manipulation;
        }
        
        /* Avatar Container */
        #avatar-container {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: calc(100% - 200px);
            z-index: 1;
        }
        
        iframe {
            width: 100%;
            height: 100%;
            border: none;
        }
        
        /* Touch Control Panel */
        #control-panel {
            position: fixed;
            bottom: 0;
            left: 0;
            right: 0;
            height: 200px;
            background: linear-gradient(transparent, rgba(0,0,0,0.9));
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            padding: 20px;
            z-index: 10;
            gap: 15px;
        }
        
        /* Record Button */
        #record-btn {
            width: 100px;
            height: 100px;
            border-radius: 50%;
            border: 4px solid rgba(255,255,255,0.3);
            background: radial-gradient(circle, #3b82f6 0%, #2563eb 100%);
            color: white;
            font-size: 40px;
            cursor: pointer;
            box-shadow: 0 4px 30px rgba(59, 130, 246, 0.5);
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            user-select: none;
            -webkit-user-select: none;
        }
        
        #record-btn:active {
            transform: scale(0.95);
            box-shadow: 0 2px 15px rgba(59, 130, 246, 0.3);
        }
        
        #record-btn.recording {
            background: radial-gradient(circle, #ef4444 0%, #dc2626 100%);
            border-color: rgba(239, 68, 68, 0.5);
            box-shadow: 0 4px 30px rgba(239, 68, 68, 0.5);
            animation: pulse-record 1s infinite;
        }
        
        #record-btn.processing {
            background: radial-gradient(circle, #f59e0b 0%, #d97706 100%);
            border-color: rgba(245, 158, 11, 0.5);
        }
        
        #record-btn.speaking {
            background: radial-gradient(circle, #10b981 0%, #059669 100%);
            border-color: rgba(16, 185, 129, 0.5);
            box-shadow: 0 4px 30px rgba(16, 185, 129, 0.5);
        }
        
        @keyframes pulse-record {
            0%, 100% { transform: scale(1); opacity: 1; }
            50% { transform: scale(1.05); opacity: 0.9; }
        }
        
        /* Status Text */
        #status-text {
            font-size: 16px;
            color: rgba(255,255,255,0.8);
            text-align: center;
            min-height: 24px;
            font-weight: 500;
        }
        
        #status-text.recording {
            color: #ef4444;
        }
        
        #transcript-preview {
            font-size: 14px;
            color: rgba(255,255,255,0.6);
            text-align: center;
            max-width: 90%;
            min-height: 20px;
            overflow: hidden;
            text-overflow: ellipsis;
            white-space: nowrap;
        }
        
        /* Conversation Log */
        #conversation-log {
            position: fixed;
            top: 10px;
            left: 10px;
            right: 10px;
            max-height: 35vh;
            overflow-y: auto;
            z-index: 5;
            display: flex;
            flex-direction: column;
            gap: 8px;
            pointer-events: none;
        }
        
        .message {
            background: rgba(0, 0, 0, 0.7);
            backdrop-filter: blur(10px);
            padding: 10px 14px;
            border-radius: 18px;
            max-width: 85%;
            animation: slideIn 0.3s ease;
            pointer-events: auto;
            font-size: 14px;
            line-height: 1.4;
        }
        
        .message.user {
            align-self: flex-end;
            background: rgba(59, 130, 246, 0.25);
            border: 1px solid rgba(59, 130, 246, 0.4);
        }
        
        .message.assistant {
            align-self: flex-start;
            background: rgba(16, 185, 129, 0.25);
            border: 1px solid rgba(16, 185, 129, 0.4);
        }
        
        @keyframes slideIn {
            from { opacity: 0; transform: translateY(-10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        
        /* Settings Button */
        #settings-btn {
            position: fixed;
            top: 15px;
            right: 15px;
            width: 44px;
            height: 44px;
            border-radius: 50%;
            border: none;
            background: rgba(0,0,0,0.5);
            color: white;
            font-size: 20px;
            cursor: pointer;
            z-index: 20;
            backdrop-filter: blur(10px);
        }
        
        /* Settings Modal */
        #settings-modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(0,0,0,0.9);
            z-index: 100;
            padding: 20px;
            flex-direction: column;
            justify-content: center;
        }
        
        #settings-modal.open {
            display: flex;
        }
        
        #settings-modal h2 {
            margin-bottom: 20px;
            text-align: center;
        }
        
        #settings-modal input {
            width: 100%;
            padding: 12px;
            border-radius: 8px;
            border: 1px solid #444;
            background: #222;
            color: white;
            font-size: 16px;
            margin-bottom: 15px;
        }
        
        #settings-modal button {
            padding: 12px 24px;
            background: #3b82f6;
            color: white;
            border: none;
            border-radius: 8px;
            font-size: 16px;
            cursor: pointer;
            margin-bottom: 10px;
        }
        
        #settings-modal .close-btn {
            background: #666;
        }
    </style>
</head>
<body>
    <!-- Settings Button -->
    <button id="settings-btn" onclick="toggleSettings()">‚öôÔ∏è</button>
    
    <!-- Settings Modal -->
    <div id="settings-modal">
        <h2>Ë®≠ÂÆö</h2>
        <div>OpenAI API Key:</div>
        <input type="password" id="api-key" placeholder="sk-...">
        
        <button onclick="saveSettings()">‰øùÂ≠ò</button>
        <button class="close-btn" onclick="toggleSettings()">Èñâ„Åò„Çã</button>
    </div>
    
    <!-- Conversation Log -->
    <div id="conversation-log"></div>
    
    <!-- Avatar -->
    <div id="avatar-container">
        <iframe src="https://meeting-ai-avatar.netlify.app" id="avatar-frame"></iframe>
    </div>
    
    <!-- Touch Controls -->
    <div id="control-panel">
        <div id="status-text">„Çø„ÉÉ„Éó&„Éõ„Éº„É´„Éâ„ÅßË©±„Åô</div>
        <div id="transcript-preview"></div>
        
        <button id="record-btn">üé§</button>
    </div>

    <script>
        // State
        let isRecording = false;
        let mediaRecorder = null;
        let audioChunks = [];
        let recognition = null;
        let apiKey = localStorage.getItem('openai_key') || '';
        
        // DOM
        const recordBtn = document.getElementById('record-btn');
        const statusText = document.getElementById('status-text');
        const transcriptPreview = document.getElementById('transcript-preview');
        const conversationLog = document.getElementById('conversation-log');
        const avatarFrame = document.getElementById('avatar-frame');
        
        // Initialize
        if (apiKey) {
            document.getElementById('api-key').value = apiKey;
        }
        
        // Touch events
        recordBtn.addEventListener('touchstart', startRecording, {passive: false});
        recordBtn.addEventListener('touchend', stopRecording);
        recordBtn.addEventListener('mousedown', startRecording);
        recordBtn.addEventListener('mouseup', stopRecording);
        recordBtn.addEventListener('mouseleave', stopRecording);
        
        // Prevent context menu on long press
        recordBtn.addEventListener('contextmenu', e => e.preventDefault());
        
        async function startRecording(e) {
            e.preventDefault();
            if (isRecording) return;
            
            if (!apiKey) {
                alert('Ë®≠ÂÆö„Åã„ÇâOpenAI API Key„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ');
                toggleSettings();
                return;
            }
            
            try {
                // Request microphone
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                isRecording = true;
                recordBtn.classList.add('recording');
                statusText.textContent = 'Èå≤Èü≥‰∏≠...Èõ¢„Åô„Å®ÈÄÅ‰ø°';
                statusText.classList.add('recording');
                transcriptPreview.textContent = '';
                
                // Notify avatar
                notifyAvatar('listening');
                
                // Start Web Speech API
                if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                    recognition = new SpeechRecognition();
                    recognition.lang = 'ja-JP';
                    recognition.continuous = true;
                    recognition.interimResults = true;
                    
                    recognition.onresult = (event) => {
                        let transcript = '';
                        for (let i = event.resultIndex; i < event.results.length; i++) {
                            transcript += event.results[i][0].transcript;
                        }
                        transcriptPreview.textContent = transcript;
                    };
                    
                    recognition.start();
                }
                
            } catch (err) {
                console.error('Microphone error:', err);
                statusText.textContent = '„Éû„Ç§„ÇØË®±ÂèØ„ÅåÂøÖË¶Å„Åß„Åô';
                isRecording = false;
            }
        }
        
        async function stopRecording(e) {
            if (!isRecording) return;
            
            isRecording = false;
            recordBtn.classList.remove('recording');
            recordBtn.classList.add('processing');
            statusText.classList.remove('recording');
            statusText.textContent = 'Âá¶ÁêÜ‰∏≠...';
            
            // Stop recognition
            if (recognition) {
                recognition.stop();
            }
            
            const transcript = transcriptPreview.textContent.trim();
            if (transcript) {
                await processMessage(transcript);
            } else {
                statusText.textContent = '„Çø„ÉÉ„Éó&„Éõ„Éº„É´„Éâ„ÅßË©±„Åô';
                recordBtn.classList.remove('processing');
            }
        }
        
        async function processMessage(text) {
            addMessage('user', text);
            
            notifyAvatar('thinking');
            
            try {
                // Call OpenAI
                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${apiKey}`
                    },
                    body: JSON.stringify({
                        model: 'gpt-4o-mini',
                        messages: [
                            { role: 'system', content: 'Êó•Êú¨Ë™û„ÅßÁ∞°ÊΩî„Å´Á≠î„Åà„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ' },
                            { role: 'user', content: text }
                        ],
                        max_tokens: 150
                    })
                });
                
                const data = await response.json();
                const reply = data.choices[0].message.content;
                
                addMessage('assistant', reply);
                await speak(reply);
                
            } catch (err) {
                console.error('Error:', err);
                statusText.textContent = '„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü';
            }
            
            recordBtn.classList.remove('processing');
            statusText.textContent = '„Çø„ÉÉ„Éó&„Éõ„Éº„É´„Éâ„ÅßË©±„Åô';
            transcriptPreview.textContent = '';
        }
        
        async function speak(text) {
            recordBtn.classList.add('speaking');
            notifyAvatar('speaking_start', text);
            
            try {
                // OpenAI TTS
                const response = await fetch('https://api.openai.com/v1/audio/speech', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${apiKey}`
                    },
                    body: JSON.stringify({
                        model: 'tts-1',
                        input: text,
                        voice: 'nova'
                    })
                });
                
                const audioBlob = await response.blob();
                const audioUrl = URL.createObjectURL(audioBlob);
                const audio = new Audio(audioUrl);
                
                audio.onended = () => {
                    recordBtn.classList.remove('speaking');
                    notifyAvatar('speaking_end');
                };
                
                await audio.play();
                
            } catch (err) {
                // Fallback
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = 'ja-JP';
                utterance.onend = () => {
                    recordBtn.classList.remove('speaking');
                    notifyAvatar('speaking_end');
                };
                speechSynthesis.speak(utterance);
            }
        }
        
        function addMessage(sender, text) {
            const msg = document.createElement('div');
            msg.className = `message ${sender}`;
            msg.textContent = text;
            conversationLog.appendChild(msg);
            conversationLog.scrollTop = conversationLog.scrollHeight;
        }
        
        function notifyAvatar(type, data = null) {
            avatarFrame.contentWindow.postMessage({ type, data }, '*');
        }
        
        function toggleSettings() {
            document.getElementById('settings-modal').classList.toggle('open');
        }
        
        function saveSettings() {
            apiKey = document.getElementById('api-key').value;
            localStorage.setItem('openai_key', apiKey);
            toggleSettings();
            statusText.textContent = 'Ë®≠ÂÆö‰øùÂ≠òÂÆå‰∫Ü';
        }
    </script>
</body>
</html>
